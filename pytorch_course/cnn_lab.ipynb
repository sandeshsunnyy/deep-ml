{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "407004b3",
   "metadata": {},
   "source": [
    "# Data Pipeline\n",
    "\n",
    "We don't have to build the model around the entire classes. We can select a small subset of classes to start with and then slowly scale after checking performance. \n",
    "\n",
    "# CNN: Key Layers\n",
    "\n",
    "## Convolutional Layer (nn.Conv2d)\n",
    "\n",
    "This is the core building block of a CNN, using learnable filters to scan the image for visual features. The output is a set of \"feature maps\" that highlight where in the image these patterns appear.\n",
    "\n",
    "- in_channels: The number of channels from the previous layer; for the first layer, this is 3 for the RGB color channels.\n",
    "- out_channels: The number of filters the layer will learn, determining the number of output feature maps.\n",
    "- kernel_size: The dimensions of the filter, such as a 3x3 grid that examines a pixel and its immediate neighbors.\n",
    "- padding: Adds a border around the image, allowing the kernel to process edge pixels while preserving the image's dimensions.\n",
    "\n",
    "## ReLU Activation Function (nn.ReLU)\n",
    "\n",
    "An activation function that introduces non-linearity by changing all negative values in the feature maps to zero. This helps the model learn more complex patterns.\n",
    "\n",
    "## Max Pooling Layer (nn.MaxPool2d)\n",
    "\n",
    "This layer downsamples the feature maps by reducing their height and width, which makes the network more efficient. It slides a window over the feature map and keeps only the single largest value from that window, discarding the rest.\n",
    "\n",
    "- kernel_size: The size of the window to perform pooling on, such as a 2x2 area.\n",
    "- stride: The step size the window moves across the image. A stride of 2 with a 2x2 kernel will halve the feature map's dimensions.\n",
    "\n",
    "## Flatten Layer (nn.Flatten)\n",
    "\n",
    "A utility layer that unrolls the 2D feature maps into a single 1D vector. This is a necessary step to prepare the data for the fully connected linear layers.\n",
    "\n",
    "## Linear Layer (nn.Linear)\n",
    "\n",
    "Also known as a fully connected layer, it performs the final classification. It combines the features learned by the convolutional layers into a final prediction.\n",
    "\n",
    "## Dropout Layer (nn.Dropout)\n",
    "\n",
    "A regularization technique that helps prevent overfitting by randomly setting a fraction of neuron activations to zero during training. This forces the network to learn more robust features instead of relying too heavily on any single pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5df09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "\n",
    "    def __init__(self, num_of_output_classes: int):\n",
    "        \n",
    "        super(SimpleCNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, num_of_output_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5d845c",
   "metadata": {},
   "source": [
    "# Initialize Loss Function and Optimizer\n",
    "\n",
    "We'll use **nn.CrossEntropyLoss**. This is the standard loss function for multi-class classification tasks as it's designed to measure the error when a model has to choose one class from several possibilities.\n",
    "\n",
    "We'll use the **Adam** optimizer. This is a popular and efficient algorithm that updates the model's weights to minimize the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad1ac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# prototype_model is the object of class SimpleCNN we create.\n",
    "optimizer_prototype = optim.Adam(prototype_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b3f76a",
   "metadata": {},
   "source": [
    "# Dynamic Graphs\n",
    "\n",
    "Earlier Deep learning frameworks needed to have the computational graph, which are the compute steps taken by a model for arriving at a result, structured and defined beforehand. Meaning debugging, branching etc. was too difficult due to this rigid structure. Much like nn.Sequential() where the computation assumes a fixed path.\n",
    "\n",
    "But PyTorch gives us flexibility in design as it allows dynamic building on computational graphs. Graphs are built during the forward pass and persists during backward pass. But when it is time to do forward pass again, the old graph is discarded and a new one is created. Thus giving us much flexibility to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ca23d8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2524778c",
   "metadata": {},
   "source": [
    "# Modular Architectures\n",
    "\n",
    "The above CNN code appears a bit redundant. Too many repititions. But this is actually a good thing as writing it all down gives us an idea of how the overall flow looks like. Then you could identify patterns and refactor your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6528bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, channel_in, channel_out):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=channel_in, out_channels=channel_out, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "    \n",
    "class CNNModel(nn.Module):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            ConvLayer(3, 32),\n",
    "            ConvLayer(32, 64),\n",
    "            ConvLayer(64, 128)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128 * 4 * 4, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280afe0f",
   "metadata": {},
   "source": [
    "# How do you see what's inside your model?\n",
    "\n",
    "## How many parameters does your model have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff5d572",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(param.numel() for param in model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffa07ee",
   "metadata": {},
   "source": [
    "This just gives you a number, but if you need more details, use this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd51a236",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    # print name and param.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a143697f",
   "metadata": {},
   "source": [
    "For printing top-level layers like the custom ones we designed, we can also use model.named_children(). But this only gives us a top level view. If layers like sequential is defined within the layer, we won't be able to see that. \n",
    "\n",
    "For going deeper use model.named_modules()\n",
    "\n",
    "In case of errors, we can inspect the shapes of each output in the forward pass."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
