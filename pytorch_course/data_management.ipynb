{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d37d1333",
   "metadata": {},
   "source": [
    "# Data Management in PyTorch\n",
    "\n",
    "## Datasets\n",
    "\n",
    "Often times the data that is provided to us may not be in a form that can be directly used in classes like DataLoader. For example the image names may be generic, and the labels might be in some other file (like a .mat file). In such cases. It is crucial that we learn how to define our own Datasets and Dataloaders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9e7ca2",
   "metadata": {},
   "source": [
    "## Data Access\n",
    "### Defining our own Custom Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e06fd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class OxfordFlowersDataset(Dataset):\n",
    "\n",
    "  def __init__(self, root_dir):\n",
    "    self.root_dir = root_dir\n",
    "    self.img_dir = os.path.join(root_dir, 'images')\n",
    "\n",
    "    labels_matlab = scipy.io.loadmat(os.path.join(root_dir, 'imagelabels.mat'))\n",
    "\n",
    "    self.labels = labels_matlab['labels'][0] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412b3187",
   "metadata": {},
   "source": [
    "Here the method adopted is called Lazy loading of Data, because if we initialize the class with data as it is, it uses up alot of RAM, which is unnecessary. Instead, we just mention where to find the data.\n",
    "\n",
    "labels are adjusted by subtracting 1 because PyTorch expects that the class labels start from 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22703e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __len__(self):\n",
    "  return len(self.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1c8460",
   "metadata": {},
   "source": [
    "Used for returning the total number of samples in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca7334f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def __getitem__(self, idx):\n",
    "\n",
    "  img_name = f'image_{idx+1:05d}.jpg'\n",
    "  img_path = os.path.join(self.img_dir, img_name)\n",
    "\n",
    "  image = Image.open(img_path)\n",
    "  label = self.labels[idx]\n",
    "\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438de586",
   "metadata": {},
   "source": [
    "This dunder function is used to return the image and its corresponding label for the index provided. img_name depends on the actual data in the directory. This only works for the image pattern in the actual dataset. \n",
    "\n",
    "Also here idx is incremented by 1 because the dataset images start with image_00001. If 1 was not added, it would have taken image number 00000 (or image_00000) which does not exist. \n",
    "\n",
    "So study the data, especially its metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd22cc06",
   "metadata": {},
   "source": [
    "## Transform Pipelines (Quality)\n",
    "\n",
    "### Learning why raw data won't work\n",
    "\n",
    "Batching won't work because pytorch expects that the items in a batch are of same dimensions. Which is rarely the case for image data. Also, PyTorch expects tensors, not image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4835f417",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "  transforms.Resize(256),\n",
    "  transforms.CenterCrop(224),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ec8f5f",
   "metadata": {},
   "source": [
    "transforms.Resize(256) resizes the shorter edge to 256 whilst preserving the aspect ratio of the image. Hard resizing where we give both dimensions (256, 256) would distort the image. \n",
    "\n",
    "Then transforms.CenterCrop(224) is used to obtain the middle portion (the 224x224 square image) of the image.\n",
    "\n",
    "Now to convert the images into tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e86479",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "  transforms.Resize(256),\n",
    "  transforms.CenterCrop(224),\n",
    "  transforms.ToTensor(),        #  <------- Add this\n",
    "  transforms.Normalize(mean= [...],\n",
    "                        std= [...])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72690e0e",
   "metadata": {},
   "source": [
    "ToTensor() is called 'The tensor Bridge'. Before the bridge the data type is image. After the bridge, the data is tensor. So applying transforms that could only be applied to tensors to images would cause errors. So handle that properly.\n",
    "\n",
    "Adding transforms to the OxfordFlowersDataset class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ad43b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OxfordFlowersDataset(Dataset):\n",
    "\n",
    "  def __init__(self, root_dir, transform = None):\n",
    "    # all other code\n",
    "    self.transform = transform\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    # all other code\n",
    "    if self.transform:\n",
    "      image = self.transform(image)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd79f5c",
   "metadata": {},
   "source": [
    "Now it could be batched:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835dff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a28350",
   "metadata": {},
   "source": [
    "For debugging, Take single datapoints and apply transforms individually. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6fb703",
   "metadata": {},
   "source": [
    "## DataLoader\n",
    "\n",
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74481f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "  dataset, [train_size, val_size, test_size]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdea11e",
   "metadata": {},
   "source": [
    "This gives a good mix the entire data and distributes them according to the sizes mentioned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d71d36e",
   "metadata": {},
   "source": [
    "### Batching using DataLoader\n",
    "\n",
    "iterating through the dataloader object gives us batch-wise data.\n",
    "For iterating through the first batch without starting a loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bb5e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, label = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b1a8db",
   "metadata": {},
   "source": [
    "## Bug-proofing\n",
    "\n",
    "### On-the-fly transformation of PyTorch\n",
    "\n",
    "Random transforms are applied to the training dataset as it is loaded, without extra memory usages, so that the model see different versions of the same image each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eed2fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "  #Random augmentation transforms\n",
    "  transforms.RandomHorizontalFlip(p=0.5),\n",
    "  transforms.RandomRotation(degrees=10),\n",
    "  transforms.ColorJitter(brightness=0.2),\n",
    "\n",
    "  #Other preprocessing steps\n",
    "  transforms.Resize(256),\n",
    "  transforms.CenterCrop(224),\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize(mean= [...],\n",
    "                        std= [...])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99a5d0f",
   "metadata": {},
   "source": [
    "\n",
    "### Corrupted files (Gracefully handling)\n",
    "\n",
    "In __getitem__ function include:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68b29b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.verify()\n",
    "image = Image.open(img_path)      #        <---- Reopen the image, because verify, closes the file.\n",
    "\n",
    "if image.size[0] < 32 or image.size[1] < 32:\n",
    "  raise ValueError(f\"Image too small\")\n",
    "\n",
    "if image.mode != 'RGB':      #        <---- Converting to RGB\n",
    "  image = image.convert('RGB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f0e6c0",
   "metadata": {},
   "source": [
    "In case of other Exceptions, take the next idx:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb93fce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_idx = (idx + 1) % len(self)\n",
    "return self.__getitem__(next_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a77af3a",
   "metadata": {},
   "source": [
    "### Monitoring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e576c26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __getitem__(self, idx):\n",
    "  import time\n",
    "  start_time = time.time()\n",
    "\n",
    "  self.access_counts[idx] = self.access_counts.get(idx, 0) + 1\n",
    "\n",
    "  result = super().__getitem__(idx)\n",
    "\n",
    "  load_time = time.time() - start_time\n",
    "  self.load_times.append(load_time)\n",
    "\n",
    "  if load_time > 1.0:\n",
    "    print(f\" Slow load for image index : {idx}\"\n",
    "          \"Time taken: {load_time:.2f}s\")\n",
    "  return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b64f73",
   "metadata": {},
   "source": [
    "#Important note on data augmentation and data subsets created using random-split\n",
    "\n",
    "Splits produced from random split references the Dataset class from which it is partitioned. So we can't change the transformations seperately. So we'll need to describe something new. \n",
    "\n",
    "**This is important because we only need augmentation transforms for training data, but regular transformations for testing and validation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4099d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubsetWithTransform(Dataset):\n",
    "    \"\"\"\n",
    "    A wrapper for a PyTorch Subset that applies a specific transformation.\n",
    "\n",
    "    This class allows for applying a different set of transformations to a\n",
    "    subset of a dataset, which is useful for creating distinct training,\n",
    "    validation, or test sets with different preprocessing steps from the\n",
    "    same base dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, subset, transform=None):\n",
    "        \"\"\"\n",
    "        Initializes the SubsetWithTransform object.\n",
    "\n",
    "        Args:\n",
    "            subset: A PyTorch Subset object containing a portion of a dataset.\n",
    "            transform (callable, optional): An optional transform to be applied\n",
    "                to the samples within this subset.\n",
    "        \"\"\"\n",
    "        # Store the original subset of the dataset.\n",
    "        self.subset = subset\n",
    "        # Store the transformations to be applied.\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the total number of samples in the subset.\n",
    "        \"\"\"\n",
    "        # Return the length of the underlying subset.\n",
    "        return len(self.subset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves a sample and applies the transform.\n",
    "\n",
    "        Args:\n",
    "            idx (int): The index of the sample to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple containing the transformed image and its label.\n",
    "        \"\"\"\n",
    "        # Get the original image and label from the underlying subset.\n",
    "        image, label = self.subset[idx]\n",
    "        # Check if a transform has been provided.\n",
    "        if self.transform:\n",
    "            # Apply the transform to the image.\n",
    "            image = self.transform(image)\n",
    "        # Return the transformed image and its label.\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d57475",
   "metadata": {},
   "source": [
    "This looks exactly like the Dataset class we'd described. But it allows us to add custom transforms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8250ffcd",
   "metadata": {},
   "source": [
    "# Robust Error Handling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d02194",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobustFlowerDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A custom dataset class with robust error handling for loading images.\n",
    "\n",
    "    This class is designed to gracefully handle issues with individual data\n",
    "    samples, such as corrupted files or incorrect formats. It logs any errors\n",
    "    and attempts to load a different sample instead of crashing.\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Initializes the dataset object.\n",
    "\n",
    "        Args:\n",
    "            root_dir (str): The root directory where the dataset is stored.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        # Store the root directory path.\n",
    "        self.root_dir = root_dir\n",
    "        # Construct the full path to the image directory.\n",
    "        self.img_dir = os.path.join(root_dir, \"jpg\")\n",
    "        # Store the optional transformations.\n",
    "        self.transform = transform\n",
    "        # Load and process the labels from the corresponding file.\n",
    "        self.labels = self.load_and_correct_labels()\n",
    "        # Initialize a list to keep track of any errors encountered.\n",
    "        self.error_logs = []\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves a sample, handling errors by trying the next available item.\n",
    "\n",
    "        Args:\n",
    "            idx (int): The index of the sample to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple containing the image and its label.\n",
    "        \"\"\"\n",
    "        # Loop to attempt loading a valid sample, preventing an infinite loop.\n",
    "        for attempt in range(len(self)):\n",
    "            # Attempt to load and process the sample.\n",
    "            try:\n",
    "                # Retrieve the image using the helper method.\n",
    "                image = self.retrieve_image(idx)\n",
    "                # Check if a transform has been provided.\n",
    "                if self.transform:\n",
    "                    # Apply the transform to the image.\n",
    "                    image = self.transform(image)\n",
    "                # Get the label for the current index.\n",
    "                label = self.labels[idx]\n",
    "                # Return the valid image and its corresponding label.\n",
    "                return image, label\n",
    "            # Catch any exception that occurs during the process.\n",
    "            except Exception as e:\n",
    "                # Log the error with its index and message.\n",
    "                self.log_error(idx, e)\n",
    "                # Move to the next index, wrapping around if necessary.\n",
    "                idx = (idx + 1) % len(self)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the total number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        # The total number of samples is the number of labels.\n",
    "        return len(self.labels)\n",
    "\n",
    "    def retrieve_image(self, idx):\n",
    "        \"\"\"\n",
    "        Loads and validates a single image from disk.\n",
    "\n",
    "        Args:\n",
    "            idx (int): The index of the image to load.\n",
    "\n",
    "        Returns:\n",
    "            PIL.Image.Image: The validated and loaded image object.\n",
    "        \"\"\"\n",
    "        # Construct the image filename based on the index.\n",
    "        img_name = f\"image_{idx+1:05d}.jpg\"\n",
    "        # Construct the full path to the image file.\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        # Open the image file to check its integrity without loading fully.\n",
    "        with Image.open(img_path) as img:\n",
    "            # Perform a quick verification of the file's structure.\n",
    "            img.verify()\n",
    "        # Re-open the image file after successful verification.\n",
    "        image = Image.open(img_path)\n",
    "        # Fully load the image data into memory.\n",
    "        image.load()\n",
    "        # Check if the image dimensions are below a minimum threshold.\n",
    "        if image.size[0] < 32 or image.size[1] < 32:\n",
    "            # Raise an error for images that are too small.\n",
    "            raise ValueError(f\"Image too small: {image.size}\")\n",
    "        # Check if the image is not in the RGB color mode.\n",
    "        if image.mode != \"RGB\":\n",
    "            # Convert the image to RGB.\n",
    "            image = image.convert(\"RGB\")\n",
    "        # Return the fully loaded and validated image.\n",
    "        return image\n",
    "\n",
    "    def load_and_correct_labels(self):\n",
    "        \"\"\"\n",
    "        Loads labels from a .mat file and adjusts them.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: An array of zero-indexed integer labels.\n",
    "        \"\"\"\n",
    "        # Load the MATLAB file containing the labels.\n",
    "        self.labels_mat = scipy.io.loadmat(\n",
    "            os.path.join(self.root_dir, \"imagelabels.mat\")\n",
    "        )\n",
    "        # Extract the labels array and correct for zero-based indexing.\n",
    "        labels = self.labels_mat[\"labels\"][0] - 1\n",
    "        # Truncate the dataset to the first 10 labels for quick testing.\n",
    "        labels = labels[:10]\n",
    "        # Return the processed labels.\n",
    "        return labels\n",
    "\n",
    "    def log_error(self, idx, e):\n",
    "        \"\"\"\n",
    "        Records the details of an error encountered during data loading.\n",
    "\n",
    "        Args:\n",
    "            idx (int): The index of the problematic sample.\n",
    "            e (Exception): The exception object that was raised.\n",
    "        \"\"\"\n",
    "        # Construct the filename of the problematic image.\n",
    "        img_name = f\"image_{idx + 1:05d}.jpg\"\n",
    "        # Construct the full path to the image file.\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        # Append a dictionary with error details to the log.\n",
    "        self.error_logs.append(\n",
    "            {\n",
    "                \"index\": idx,\n",
    "                \"error\": str(e),\n",
    "                \"path\": img_path if \"img_path\" in locals() else \"unknown\",\n",
    "            }\n",
    "        )\n",
    "        # Print a warning to the console about the skipped image.\n",
    "        print(f\"Warning: Skipping corrupted image {idx}: {e}\")\n",
    "\n",
    "    def get_error_summary(self):\n",
    "        \"\"\"\n",
    "        Prints a summary of all errors encountered during dataset processing.\n",
    "        \"\"\"\n",
    "        # Check if the error log is empty.\n",
    "        if not self.error_logs:\n",
    "            # Print a message indicating the dataset is clean.\n",
    "            print(\"No errors encountered - dataset is clean!\")\n",
    "        else:\n",
    "            # Print the total number of problematic images found.\n",
    "            print(f\"\\nEncountered {len(self.error_logs)} problematic images:\")\n",
    "            # Iterate through the first few logged errors.\n",
    "            for error in self.error_logs[:5]:\n",
    "                # Print the details of an individual error.\n",
    "                print(f\"  Index {error['index']}: {error['error']}\")\n",
    "            # Check if there are more errors than were displayed.\n",
    "            if len(self.error_logs) > 5:\n",
    "                # Print a summary of the remaining errors.\n",
    "                print(f\"  ... and {len(self.error_logs) - 5} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed661c3",
   "metadata": {},
   "source": [
    "The above implementation incorporates robust error handling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
