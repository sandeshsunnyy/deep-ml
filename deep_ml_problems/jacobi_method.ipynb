{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2546cdb3",
   "metadata": {},
   "source": [
    "# Jacobi Method \n",
    "\n",
    "Instead of figuring out the solutions the regular way, Jacobi method works by a sort of iterative approach where approximate solutions are obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499bfbfd",
   "metadata": {},
   "source": [
    "Consider the 2 equations: \n",
    "\n",
    "3x + y = 5\n",
    "x + 2y = 5\n",
    "\n",
    "The point of intersection of these two lines is the solution. But instead of trying to find the solutions directly, we split the equations so that they would represent something different:\n",
    "\n",
    "x_new = 5 - y_old / 3\n",
    "y_new = 5 - x_old / 2\n",
    "\n",
    "We'll use these equations, to guess the position of x and y coordinates. \n",
    "\n",
    "We'll use the initial value of x_old and y_old as 0. \n",
    "\n",
    "So x_new = 5/3, y_new = 5/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b707eb4",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/sandeshsunnyy/deep-ml/blob/main/deep_ml_problems/jacobi_img/first.png?raw=true \"My favorite view\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1364133f",
   "metadata": {},
   "source": [
    "As we can see in the figure, the value is a bit above the value that we require i.e. (1,2). So we should do the calculation again. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c508233",
   "metadata": {},
   "source": [
    "What follows is a series of back-and-forth 'dancing' of the values of x and y, until it finally converges at a an approximate solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0ee61b",
   "metadata": {},
   "source": [
    "![Jacobi Method Diagram](https://github.com/sandeshsunnyy/deep-ml/blob/main/deep_ml_problems/jacobi_img/second.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c8c279",
   "metadata": {},
   "source": [
    "## Shrinking Factors\n",
    "\n",
    "The method works becasue each step is smaller than the previous ones. \n",
    "x_new = ...-1/3 * y_old.    <--- Variation in y_old is being scaled down by a factor of 1/3\n",
    "\n",
    "y_new = ... -1/2 * x_old.   <--- Variation in x_old is being scaled down by a facror of 1/2.\n",
    "\n",
    "if the scaling factor was greater than 1, instead of shrinking, it would have exploded. And we wouldn't have obtained convergence. \n",
    "\n",
    "The important point is, in the first equation, variable x is trying to achieve its optimal state, but the progress is disturbed by the varibale y and its 'pull'. In other words, y pulls x from reaching its optimal state. So we try to lessen the effect of y's pull (reducing error) by scaling it down. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce79da3",
   "metadata": {},
   "source": [
    "But for this to work the diagonal elements have to be greater than the sum of all off-diagonal coefficients. This is something referred to as **Strictly Diagonally Dominant**. This ensures that the noice provided by the neighbours is always less than the stability provided by the variable itself. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47491666",
   "metadata": {},
   "source": [
    "## In case of matrices and vectors this is what it means:\n",
    "\n",
    "Ax = b\n",
    "\n",
    "The vector x could thus be obtained by the following simplifications: \n",
    "\n",
    "$$\\sum_{j=1}^{n} a_{i,j} x_j = b_i$$\n",
    "\n",
    "\n",
    "$$\\underbrace{a_{i,i} x_i}_{\\text{Diagonal (Self)}} + \\underbrace{\\sum_{j=1, j \\neq i}^{n} a_{i,j} x_j}_{\\text{Off-Diagonal (Neighbors)}} = b_i$$\n",
    "\n",
    "\n",
    "$$a_{i,i} x_i = b_i - \\sum_{j \\neq i} a_{i,j} x_j$$\n",
    "\n",
    "\n",
    "$$x_i = \\frac{1}{a_{i,i}} \\left( b_i - \\sum_{j \\neq i} a_{i,j} x_j \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a1e6ad",
   "metadata": {},
   "source": [
    "The equations are simply, an expansion of normal vector dot product, subjected to seperation of diagonal (self-centering force) and off-diagonal (neighbouring force). The same equation was applied to the below solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "780e4e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sandeshsunny/Documents/Developement/GitHub/deep-ml/venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:279: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def solve_jacobi(A, b, n) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Solve Ax = b using the Jacobi iterative method for n iterations.\n",
    "    A: (m,m) tensor; b: (m,) tensor; n: number of iterations.\n",
    "    Returns a 1-D tensor of length m, rounded to 4 decimals.\n",
    "    \"\"\"\n",
    "    A_t = torch.as_tensor(A, dtype=torch.float)\n",
    "    b_t = torch.as_tensor(b, dtype=torch.float)\n",
    "    # Your implementation here\n",
    "\n",
    "    length_of_x_tensor = A_t.shape[0]\n",
    "\n",
    "    x_t = current_x_t = torch.zeros((length_of_x_tensor,))\n",
    "    \n",
    "    for _ in range(n):\n",
    "      x_t = current_x_t\n",
    "      current_x_t = torch.zeros((length_of_x_tensor,))\n",
    "      \n",
    "      for i in range(0, length_of_x_tensor):\n",
    "        # Sum of product of Aij and xj\n",
    "        calculated_term = [(A_t[i, j] * x_t[j]).item() for j in range(0, length_of_x_tensor) if i != j]\n",
    "        calculated_term_t = torch.as_tensor(calculated_term, dtype=torch.float)\n",
    "        x_t_calculated_value = ((b_t[i] - torch.sum(input=calculated_term_t).item()) * (1 / A_t[i, i])).item()\n",
    "        rounded_x_t = torch.round(torch.tensor([x_t_calculated_value], dtype=torch.float), decimals=4)\n",
    "        current_x_t[i] = rounded_x_t\n",
    "\n",
    "    return x_t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
